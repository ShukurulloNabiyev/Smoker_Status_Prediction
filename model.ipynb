{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, StratifiedKFold, learning_curve \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datalarni yuklab olamiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>relaxation</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>40.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>40.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>45.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>55.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0      55.0       170.0        80.0       92.0             1.2   \n",
       "1      30.0       170.0        80.0       94.0             1.5   \n",
       "2      45.0       170.0        75.0       84.0             1.0   \n",
       "3      55.0       150.0        55.0       85.0             0.9   \n",
       "4      45.0       160.0        55.0       72.0             0.5   \n",
       "...     ...         ...         ...        ...             ...   \n",
       "14995  40.0       170.0        70.0       81.0             1.0   \n",
       "14996  40.0       155.0        50.0       75.0             1.0   \n",
       "14997  45.0       160.0        55.0       81.0             1.2   \n",
       "14998  50.0       160.0        60.0       80.0             0.7   \n",
       "14999  55.0       175.0        75.0       85.0             0.9   \n",
       "\n",
       "       eyesight(right)  hearing(left)  hearing(right)  systolic  relaxation  \\\n",
       "0                  0.8            1.0             1.0     129.0        74.0   \n",
       "1                  1.5            1.0             1.0     128.0        84.0   \n",
       "2                  1.0            1.0             1.0     124.0        80.0   \n",
       "3                  0.5            1.0             1.0     123.0        79.0   \n",
       "4                  0.6            1.0             1.0     117.0        76.0   \n",
       "...                ...            ...             ...       ...         ...   \n",
       "14995              1.0            1.0             1.0     130.0        79.0   \n",
       "14996              1.2            1.0             1.0     100.0        60.0   \n",
       "14997              0.8            1.0             1.0     100.0        60.0   \n",
       "14998              1.0            1.0             1.0     120.0        80.0   \n",
       "14999              0.8            1.0             1.0     141.0        83.0   \n",
       "\n",
       "       ...   HDL    LDL  hemoglobin  Urine protein  serum creatinine   AST  \\\n",
       "0      ...  49.0  114.0        15.4            1.0               0.9  20.0   \n",
       "1      ...  51.0  111.0        16.2            1.0               0.9  30.0   \n",
       "2      ...  52.0  112.0        14.6            2.0               0.9  20.0   \n",
       "3      ...  61.0  119.0        13.4            1.0               0.8  25.0   \n",
       "4      ...  61.0  120.0        13.9            1.0               0.7  20.0   \n",
       "...    ...   ...    ...         ...            ...               ...   ...   \n",
       "14995  ...  47.0  106.0        15.8            1.0               0.9  19.0   \n",
       "14996  ...  51.0  106.0        14.1            1.0               0.8  22.0   \n",
       "14997  ...  39.0   97.0        16.2            1.0               0.9  25.0   \n",
       "14998  ...  88.0  151.0        14.5            1.0               0.9  19.0   \n",
       "14999  ...  55.0  110.0        13.6            1.0               0.9  20.0   \n",
       "\n",
       "        ALT   Gtp  dental caries  smoking  \n",
       "0      23.0  13.0            0.0      0.0  \n",
       "1      39.0  92.0            0.0      1.0  \n",
       "2      20.0  50.0            0.0      1.0  \n",
       "3      20.0  18.0            0.0      0.0  \n",
       "4      26.0  10.0            0.0      0.0  \n",
       "...     ...   ...            ...      ...  \n",
       "14995  20.0  25.0            1.0      1.0  \n",
       "14996  17.0  20.0            0.0      0.0  \n",
       "14997  20.0  30.0            0.0      0.0  \n",
       "14998  13.0  11.0            0.0      0.0  \n",
       "14999  27.0  19.0            0.0      0.0  \n",
       "\n",
       "[15000 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv').drop(columns=['id'])\n",
    "df_test = pd.read_csv('test.csv').drop(columns=['id'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data ustida feature engineering qilingan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Bo'yni metrlarda\n",
    "    df['Height_m'] = df['height(cm)'] / 100\n",
    "    \n",
    "    # Bo'yining kvadrati\n",
    "    df['Height_squared'] = df['Height_m'] ** 2\n",
    "    \n",
    "    # Tananing massa indeksi (BMI)\n",
    "    df['BMI'] = df['weight(kg)'] / df['Height_squared']\n",
    "    \n",
    "    # Belning bo'yiga nisbati\n",
    "    df['Waist_to_height_ratio'] = df['waist(cm)'] / df['Height_m']\n",
    "    \n",
    "    # Chap va o'ng ko'z ko'rishidagi farq\n",
    "    df['Eyesight_diff'] = df['eyesight(left)'] - df['eyesight(right)']\n",
    "    \n",
    "    # Chap va o'ng quloq eshitishidagi farq\n",
    "    df['Hearing_diff'] = df['hearing(left)'] - df['hearing(right)']\n",
    "    \n",
    "    # Sistolik va diastolik bosimlar orasidagi farq\n",
    "    df['Pulse_pressure'] = df['systolic'] - df['relaxation']\n",
    "    \n",
    "    # Qon bosimi yuqoriligi xavfi\n",
    "    df['Hypertension_risk'] = ((df['systolic'] > 140) | (df['relaxation'] > 90)).astype(int)\n",
    "    \n",
    "    # Qondagi qand miqdori xavfi\n",
    "    df['Blood_sugar_risk'] = (df['fasting blood sugar'] > 126).astype(int)\n",
    "    \n",
    "    # Yomon va yaxshi xolesterin nisbati\n",
    "    df['LDL_to_HDL_ratio'] = df['LDL'] / df['HDL']\n",
    "    \n",
    "    # Xolesterin yuqoriligi xavfi\n",
    "    df['Cholesterol_risk'] = (df['Cholesterol'] > 240).astype(int)\n",
    "    \n",
    "    # Gemoglobin miqdorining normallashtirilgan ko'rsatkichi\n",
    "    df['Hemoglobin_normalized'] = df['hemoglobin'] / 15  # Erkaklar uchun umumiy\n",
    "    \n",
    "    # Buyrak funktsiyasi indeksi\n",
    "    df['Kidney_function_index'] = df['serum creatinine'] / 1.2\n",
    "    \n",
    "    # Jigar funktsiyasi reytingi\n",
    "    df['Liver_function_score'] = df['AST'] + df['ALT'] + df['Gtp']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineering(df)\n",
    "df_test = feature_engineering(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datamizni bolib olamiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['smoking'])\n",
    "y = df['smoking']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV orqali 3 modelni eng yaxshi parametrlarni topib olamiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', max_depth=np.int64(5),\n",
      "                       min_samples_leaf=np.int64(5),\n",
      "                       min_samples_split=np.int64(7), random_state=1)\n",
      "LogisticRegression(C=np.float64(10000.0), max_iter=np.int64(274),\n",
      "                   random_state=1, solver='newton-cg')\n",
      "RandomForestClassifier(criterion='log_loss', max_depth=np.int64(15),\n",
      "                       min_samples_leaf=np.int64(1),\n",
      "                       min_samples_split=np.int64(9),\n",
      "                       n_estimators=np.int64(300), random_state=1)\n"
     ]
    }
   ],
   "source": [
    "param_dist_dt = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': np.arange(5, 11),\n",
    "    'min_samples_split': np.arange(2, 8),\n",
    "    'min_samples_leaf': np.arange(1, 6)\n",
    "}\n",
    "\n",
    "param_dist_lr = {\n",
    "    'C': np.logspace(-4, 4, 10),\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'],\n",
    "    'max_iter': np.arange(100, 301)\n",
    "}\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': np.arange(100, 401, 50),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': np.arange(9, 16),\n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'min_samples_leaf': np.arange(1, 6),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search_dt = RandomizedSearchCV(DecisionTreeClassifier(random_state=1), param_distributions=param_dist_dt, n_iter=200, scoring='roc_auc', cv=5, random_state=1, return_train_score=True)\n",
    "random_search_lr = RandomizedSearchCV(LogisticRegression(random_state=1), param_distributions=param_dist_lr, n_iter=70, scoring='roc_auc', cv=5, random_state=1, return_train_score=True)\n",
    "random_search_rf = RandomizedSearchCV(RandomForestClassifier(random_state=1), param_distributions=param_dist_rf, n_iter=200, scoring='roc_auc', cv=5, random_state=1, return_train_score=True)\n",
    "\n",
    "random_search_dt.fit(X_train, y_train)\n",
    "random_search_lr.fit(X_train, y_train)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(random_search_dt.best_estimator_)\n",
    "print(random_search_lr.best_estimator_)\n",
    "print(random_search_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best parametrlar stacking orqali birlashtirib roc_auc_scoreni koramiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8905063407908128\n"
     ]
    }
   ],
   "source": [
    "best_dt = random_search_dt.best_estimator_\n",
    "best_lr = random_search_lr.best_estimator_\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "\n",
    "estimators = [('dt', best_dt), ('lr', best_lr), ('rf', best_rf)]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bu yerda optuna orqali modelni eng yaxshi parametrlarni topamiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 19:56:58,500] A new study created in memory with name: no-name-6e3967ed-436a-427f-bfd3-692849ee9e8d\n",
      "[I 2024-10-28 19:56:58,503] A new study created in memory with name: no-name-9c6680fa-ae9b-400e-bb15-2ccc6f9d059b\n",
      "[I 2024-10-28 19:56:58,505] A new study created in memory with name: no-name-6063f27d-e4cc-4156-81b9-d72041fdf818\n",
      "[I 2024-10-28 19:56:58,646] Trial 0 finished with value: 0.8406508982858234 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8406508982858234.\n",
      "[I 2024-10-28 19:56:59,031] Trial 1 finished with value: 0.8442765214637884 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8442765214637884.\n",
      "[I 2024-10-28 19:56:59,280] Trial 2 finished with value: 0.8499043696663552 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:56:59,389] Trial 3 finished with value: 0.8330885168398326 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:56:59,515] Trial 4 finished with value: 0.8321161820544288 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:00,256] Trial 5 finished with value: 0.8210916675247732 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:00,765] Trial 6 finished with value: 0.8012836692862866 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:00,876] Trial 7 finished with value: 0.8390851150059312 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:01,291] Trial 8 finished with value: 0.8382889565084234 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:01,664] Trial 9 finished with value: 0.845587795086181 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:01,938] Trial 10 finished with value: 0.8494710808067009 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:02,199] Trial 11 finished with value: 0.8494710808067009 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:02,678] Trial 12 finished with value: 0.8496442176027317 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:03,058] Trial 13 finished with value: 0.8471950877104651 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:03,367] Trial 14 finished with value: 0.8473870240483354 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:03,629] Trial 15 finished with value: 0.8496442176027317 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:03,973] Trial 16 finished with value: 0.849383729836352 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.8499043696663552.\n",
      "[I 2024-10-28 19:57:04,239] Trial 17 finished with value: 0.8503530485814125 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:04,349] Trial 18 finished with value: 0.8372408283598697 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:04,965] Trial 19 finished with value: 0.8215572582602441 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:05,481] Trial 20 finished with value: 0.840775035113493 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:05,745] Trial 21 finished with value: 0.8497142358620134 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:06,010] Trial 22 finished with value: 0.8497142358620134 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:06,316] Trial 23 finished with value: 0.8473870240483354 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:06,581] Trial 24 finished with value: 0.8495300948054835 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:06,889] Trial 25 finished with value: 0.8468242675378039 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:06,991] Trial 26 finished with value: 0.8372980919141509 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:07,407] Trial 27 finished with value: 0.8470542541479296 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.8503530485814125.\n",
      "[I 2024-10-28 19:57:07,881] Trial 28 finished with value: 0.8521295112762122 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:07,999] Trial 29 finished with value: 0.8426264132680512 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:08,492] Trial 30 finished with value: 0.8181824838964266 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:08,784] Trial 31 finished with value: 0.8521295112762122 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:09,072] Trial 32 finished with value: 0.8521295112762122 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:09,362] Trial 33 finished with value: 0.8521295112762122 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:09,722] Trial 34 finished with value: 0.8495589867833138 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:10,306] Trial 35 finished with value: 0.8520984461514404 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:10,411] Trial 36 finished with value: 0.8348481363468518 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:10,752] Trial 37 finished with value: 0.8492491467566199 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:11,144] Trial 38 finished with value: 0.8442373735636058 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:11,247] Trial 39 finished with value: 0.8348481363468518 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:11,742] Trial 40 finished with value: 0.8209045132098904 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:12,033] Trial 41 finished with value: 0.8520984461514404 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:12,492] Trial 42 finished with value: 0.8520984461514404 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:12,882] Trial 43 finished with value: 0.8521295112762122 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:13,172] Trial 44 finished with value: 0.8521295112762122 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:13,521] Trial 45 finished with value: 0.8495589867833138 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:13,815] Trial 46 finished with value: 0.8521295112762122 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:14,156] Trial 47 finished with value: 0.8495589867833138 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:14,448] Trial 48 finished with value: 0.8521295112762122 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.8521295112762122.\n",
      "[I 2024-10-28 19:57:14,851] Trial 49 finished with value: 0.8521405155367112 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 49 with value: 0.8521405155367112.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:16,577] Trial 0 finished with value: 0.8683719634114484 and parameters: {'C': 0.49550359883630574, 'solver': 'newton-cg', 'max_iter': 228}. Best is trial 0 with value: 0.8683719634114484.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:18,642] Trial 1 finished with value: 0.8682601407525403 and parameters: {'C': 4753.428568429683, 'solver': 'liblinear', 'max_iter': 210}. Best is trial 0 with value: 0.8683719634114484.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:57:19,182] Trial 2 finished with value: 0.8656933511280496 and parameters: {'C': 406.3533175924339, 'solver': 'lbfgs', 'max_iter': 118}. Best is trial 0 with value: 0.8683719634114484.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:57:20,571] Trial 3 finished with value: 0.8663990506902314 and parameters: {'C': 12.585840838554766, 'solver': 'lbfgs', 'max_iter': 203}. Best is trial 0 with value: 0.8683719634114484.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:57:21,658] Trial 4 finished with value: 0.8669961204414613 and parameters: {'C': 0.03223938505432935, 'solver': 'lbfgs', 'max_iter': 254}. Best is trial 0 with value: 0.8683719634114484.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:57:22,605] Trial 5 finished with value: 0.8642030422921483 and parameters: {'C': 3.5580683560500495, 'solver': 'lbfgs', 'max_iter': 115}. Best is trial 0 with value: 0.8683719634114484.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:25,344] Trial 6 finished with value: 0.8688511651706451 and parameters: {'C': 38.19360110204807, 'solver': 'newton-cg', 'max_iter': 287}. Best is trial 6 with value: 0.8688511651706451.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:26,757] Trial 7 finished with value: 0.8684921028178734 and parameters: {'C': 0.262279854627442, 'solver': 'liblinear', 'max_iter': 135}. Best is trial 6 with value: 0.8688511651706451.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-28 19:57:29,927] Trial 8 finished with value: 0.8630937085947075 and parameters: {'C': 5722.066387731074, 'solver': 'saga', 'max_iter': 137}. Best is trial 6 with value: 0.8688511651706451.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:32,925] Trial 9 finished with value: 0.8694106654411666 and parameters: {'C': 630.4001075257163, 'solver': 'newton-cg', 'max_iter': 168}. Best is trial 9 with value: 0.8694106654411666.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:34,086] Trial 10 finished with value: 0.858607563883743 and parameters: {'C': 0.00014292035272361528, 'solver': 'newton-cg', 'max_iter': 171}. Best is trial 9 with value: 0.8694106654411666.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:36,950] Trial 11 finished with value: 0.8692412024463391 and parameters: {'C': 111.09127622346804, 'solver': 'newton-cg', 'max_iter': 290}. Best is trial 9 with value: 0.8694106654411666.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:40,487] Trial 12 finished with value: 0.8690885655843296 and parameters: {'C': 192.9560431322031, 'solver': 'newton-cg', 'max_iter': 299}. Best is trial 9 with value: 0.8694106654411666.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:43,199] Trial 13 finished with value: 0.8690751166579126 and parameters: {'C': 328.41607258423176, 'solver': 'newton-cg', 'max_iter': 171}. Best is trial 9 with value: 0.8694106654411666.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-28 19:57:48,164] Trial 14 finished with value: 0.8654241332446639 and parameters: {'C': 57.86677184587604, 'solver': 'saga', 'max_iter': 251}. Best is trial 9 with value: 0.8694106654411666.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:51,078] Trial 15 finished with value: 0.8695870794301414 and parameters: {'C': 1764.2220424236746, 'solver': 'newton-cg', 'max_iter': 182}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:53,679] Trial 16 finished with value: 0.8690368936721231 and parameters: {'C': 6129.175229790015, 'solver': 'newton-cg', 'max_iter': 166}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:57:55,435] Trial 17 finished with value: 0.8664492678672715 and parameters: {'C': 0.0027685621880162124, 'solver': 'newton-cg', 'max_iter': 183}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-28 19:57:58,373] Trial 18 finished with value: 0.8635606890305034 and parameters: {'C': 1170.0755301625522, 'solver': 'saga', 'max_iter': 150}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:00,413] Trial 19 finished with value: 0.868274951165364 and parameters: {'C': 6.571332088487284, 'solver': 'liblinear', 'max_iter': 224}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:03,104] Trial 20 finished with value: 0.8689199955072624 and parameters: {'C': 1292.1901000418184, 'solver': 'newton-cg', 'max_iter': 191}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:05,943] Trial 21 finished with value: 0.8690207951438473 and parameters: {'C': 74.97606872389817, 'solver': 'newton-cg', 'max_iter': 269}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:08,519] Trial 22 finished with value: 0.8689962815197532 and parameters: {'C': 1422.8403414845675, 'solver': 'newton-cg', 'max_iter': 150}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:11,154] Trial 23 finished with value: 0.8686521794903268 and parameters: {'C': 19.564395074294712, 'solver': 'newton-cg', 'max_iter': 219}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:14,467] Trial 24 finished with value: 0.869320001008686 and parameters: {'C': 135.99533996869692, 'solver': 'newton-cg', 'max_iter': 239}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:16,678] Trial 25 finished with value: 0.8683111750827237 and parameters: {'C': 1.9226688626841373, 'solver': 'newton-cg', 'max_iter': 240}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:19,235] Trial 26 finished with value: 0.8691023750059262 and parameters: {'C': 936.7262426175608, 'solver': 'newton-cg', 'max_iter': 191}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:20,980] Trial 27 finished with value: 0.8682737850690632 and parameters: {'C': 8943.972496895416, 'solver': 'liblinear', 'max_iter': 101}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-28 19:58:24,245] Trial 28 finished with value: 0.8636956389538246 and parameters: {'C': 0.06598697238307293, 'solver': 'saga', 'max_iter': 155}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:26,430] Trial 29 finished with value: 0.8683616239710943 and parameters: {'C': 0.5950150820414832, 'solver': 'newton-cg', 'max_iter': 233}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:29,790] Trial 30 finished with value: 0.869311865439817 and parameters: {'C': 400.58296279265306, 'solver': 'newton-cg', 'max_iter': 210}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:32,629] Trial 31 finished with value: 0.869370146584 and parameters: {'C': 332.18674888938216, 'solver': 'newton-cg', 'max_iter': 212}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:34,978] Trial 32 finished with value: 0.8689681050220447 and parameters: {'C': 2147.889201269127, 'solver': 'newton-cg', 'max_iter': 189}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:37,335] Trial 33 finished with value: 0.8688831189173996 and parameters: {'C': 210.91082467105866, 'solver': 'newton-cg', 'max_iter': 214}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:39,787] Trial 34 finished with value: 0.8687608235591805 and parameters: {'C': 19.483380656474427, 'solver': 'newton-cg', 'max_iter': 244}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:58:40,502] Trial 35 finished with value: 0.8664489248562337 and parameters: {'C': 536.403400024041, 'solver': 'lbfgs', 'max_iter': 201}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:42,619] Trial 36 finished with value: 0.8682231444331162 and parameters: {'C': 2422.89537490925, 'solver': 'liblinear', 'max_iter': 269}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:58:43,714] Trial 37 finished with value: 0.8661771988516562 and parameters: {'C': 118.10956743533242, 'solver': 'lbfgs', 'max_iter': 179}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:46,489] Trial 38 finished with value: 0.8689144590187547 and parameters: {'C': 41.524752381614164, 'solver': 'newton-cg', 'max_iter': 201}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:49,099] Trial 39 finished with value: 0.869013207296183 and parameters: {'C': 3069.239265972264, 'solver': 'newton-cg', 'max_iter': 263}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-10-28 19:58:49,693] Trial 40 finished with value: 0.8664697046294212 and parameters: {'C': 596.0428954444435, 'solver': 'lbfgs', 'max_iter': 161}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:52,206] Trial 41 finished with value: 0.8693183524444976 and parameters: {'C': 388.736479634232, 'solver': 'newton-cg', 'max_iter': 209}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:55,785] Trial 42 finished with value: 0.8693919552397842 and parameters: {'C': 241.14721052267194, 'solver': 'newton-cg', 'max_iter': 213}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:58:58,157] Trial 43 finished with value: 0.8685471861186314 and parameters: {'C': 9.636420350685095, 'solver': 'newton-cg', 'max_iter': 231}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:59:01,025] Trial 44 finished with value: 0.8692122879944895 and parameters: {'C': 140.06758984637355, 'solver': 'newton-cg', 'max_iter': 137}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:59:03,371] Trial 45 finished with value: 0.8688427925363154 and parameters: {'C': 4292.066869886319, 'solver': 'newton-cg', 'max_iter': 179}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-10-28 19:59:07,852] Trial 46 finished with value: 0.8650574407908842 and parameters: {'C': 26.400162633602537, 'solver': 'saga', 'max_iter': 221}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:59:09,514] Trial 47 finished with value: 0.8683886724629554 and parameters: {'C': 3.3885879006630386, 'solver': 'newton-cg', 'max_iter': 237}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:59:11,656] Trial 48 finished with value: 0.8681982106804277 and parameters: {'C': 240.54569874921194, 'solver': 'liblinear', 'max_iter': 248}. Best is trial 15 with value: 0.8695870794301414.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16396\\987172121.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
      "[I 2024-10-28 19:59:14,449] Trial 49 finished with value: 0.8691191552428702 and parameters: {'C': 72.1741547742332, 'solver': 'newton-cg', 'max_iter': 260}. Best is trial 15 with value: 0.8695870794301414.\n",
      "[I 2024-10-28 19:59:25,462] Trial 0 finished with value: 0.8676229736721217 and parameters: {'n_estimators': 288, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 0 with value: 0.8676229736721217.\n",
      "[I 2024-10-28 19:59:38,877] Trial 1 finished with value: 0.8811393924937274 and parameters: {'n_estimators': 156, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 1 with value: 0.8811393924937274.\n",
      "[I 2024-10-28 19:59:44,547] Trial 2 finished with value: 0.8672377651581981 and parameters: {'n_estimators': 150, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 1 with value: 0.8811393924937274.\n",
      "[I 2024-10-28 19:59:51,857] Trial 3 finished with value: 0.8673826505244815 and parameters: {'n_estimators': 193, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 1 with value: 0.8811393924937274.\n",
      "[I 2024-10-28 20:00:11,293] Trial 4 finished with value: 0.8808487426385689 and parameters: {'n_estimators': 270, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 1 with value: 0.8811393924937274.\n",
      "[I 2024-10-28 20:00:27,232] Trial 5 finished with value: 0.8809681865987855 and parameters: {'n_estimators': 213, 'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 1 with value: 0.8811393924937274.\n",
      "[I 2024-10-28 20:00:49,938] Trial 6 finished with value: 0.8817554741983124 and parameters: {'n_estimators': 289, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 6 with value: 0.8817554741983124.\n",
      "[I 2024-10-28 20:01:22,166] Trial 7 finished with value: 0.8800685353950286 and parameters: {'n_estimators': 332, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 6 with value: 0.8817554741983124.\n",
      "[I 2024-10-28 20:01:44,542] Trial 8 finished with value: 0.8817967667064106 and parameters: {'n_estimators': 286, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 8 with value: 0.8817967667064106.\n",
      "[I 2024-10-28 20:02:10,818] Trial 9 finished with value: 0.882034635480597 and parameters: {'n_estimators': 320, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:02:53,207] Trial 10 finished with value: 0.8807064388685042 and parameters: {'n_estimators': 385, 'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:03:35,651] Trial 11 finished with value: 0.8801910791161424 and parameters: {'n_estimators': 358, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:03:55,893] Trial 12 finished with value: 0.8794008318946306 and parameters: {'n_estimators': 323, 'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:04:09,080] Trial 13 finished with value: 0.8779416419600536 and parameters: {'n_estimators': 231, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:04:49,304] Trial 14 finished with value: 0.8811799477761907 and parameters: {'n_estimators': 320, 'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:04:57,472] Trial 15 finished with value: 0.8795692730261475 and parameters: {'n_estimators': 107, 'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:05:25,743] Trial 16 finished with value: 0.8798339021848751 and parameters: {'n_estimators': 397, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:05:46,366] Trial 17 finished with value: 0.8817357978699153 and parameters: {'n_estimators': 262, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:06:10,128] Trial 18 finished with value: 0.8742845500418082 and parameters: {'n_estimators': 354, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:06:31,227] Trial 19 finished with value: 0.8811819162473713 and parameters: {'n_estimators': 293, 'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:06:48,902] Trial 20 finished with value: 0.8804429590504407 and parameters: {'n_estimators': 238, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:07:12,464] Trial 21 finished with value: 0.8818160429921627 and parameters: {'n_estimators': 295, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:07:37,585] Trial 22 finished with value: 0.8815941733572281 and parameters: {'n_estimators': 307, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:08:05,270] Trial 23 finished with value: 0.8816751568499056 and parameters: {'n_estimators': 358, 'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:08:26,145] Trial 24 finished with value: 0.881725017174295 and parameters: {'n_estimators': 256, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:08:51,546] Trial 25 finished with value: 0.8809710230103803 and parameters: {'n_estimators': 344, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:09:21,958] Trial 26 finished with value: 0.8806421994420625 and parameters: {'n_estimators': 273, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:09:48,385] Trial 27 finished with value: 0.881803629239123 and parameters: {'n_estimators': 306, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:10:16,812] Trial 28 finished with value: 0.8808193229270029 and parameters: {'n_estimators': 379, 'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:10:44,551] Trial 29 finished with value: 0.8816978163782503 and parameters: {'n_estimators': 315, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 9 with value: 0.882034635480597.\n",
      "[I 2024-10-28 20:11:09,617] Trial 30 finished with value: 0.882112387051771 and parameters: {'n_estimators': 303, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 30 with value: 0.882112387051771.\n",
      "[I 2024-10-28 20:11:36,396] Trial 31 finished with value: 0.8816389994347302 and parameters: {'n_estimators': 302, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 30 with value: 0.882112387051771.\n",
      "[I 2024-10-28 20:12:04,528] Trial 32 finished with value: 0.882117465529376 and parameters: {'n_estimators': 333, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 32 with value: 0.882117465529376.\n",
      "[I 2024-10-28 20:12:32,958] Trial 33 finished with value: 0.8821725701649505 and parameters: {'n_estimators': 338, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:13:01,137] Trial 34 finished with value: 0.8821447281443527 and parameters: {'n_estimators': 336, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:13:26,985] Trial 35 finished with value: 0.8808312947427142 and parameters: {'n_estimators': 340, 'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:13:57,720] Trial 36 finished with value: 0.8821269613822285 and parameters: {'n_estimators': 371, 'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:14:23,364] Trial 37 finished with value: 0.8798771298610258 and parameters: {'n_estimators': 375, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:14:41,254] Trial 38 finished with value: 0.8719200730835712 and parameters: {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:15:13,673] Trial 39 finished with value: 0.8815965406221865 and parameters: {'n_estimators': 371, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:15:47,260] Trial 40 finished with value: 0.8798665520487159 and parameters: {'n_estimators': 336, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:16:16,293] Trial 41 finished with value: 0.8820485012052954 and parameters: {'n_estimators': 352, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:16:46,119] Trial 42 finished with value: 0.8820693161549119 and parameters: {'n_estimators': 364, 'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:17:12,750] Trial 43 finished with value: 0.8817768821870177 and parameters: {'n_estimators': 332, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:17:42,222] Trial 44 finished with value: 0.8810712156621914 and parameters: {'n_estimators': 388, 'criterion': 'log_loss', 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:17:57,229] Trial 45 finished with value: 0.8808678377633022 and parameters: {'n_estimators': 178, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:18:17,255] Trial 46 finished with value: 0.8807846308047379 and parameters: {'n_estimators': 280, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:18:42,527] Trial 47 finished with value: 0.8808751123357854 and parameters: {'n_estimators': 327, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:19:21,676] Trial 48 finished with value: 0.8811981556318808 and parameters: {'n_estimators': 312, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 33 with value: 0.8821725701649505.\n",
      "[I 2024-10-28 20:19:50,314] Trial 49 finished with value: 0.8820857033220534 and parameters: {'n_estimators': 348, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 33 with value: 0.8821725701649505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'splitter': 'best', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
      "{'C': 1764.2220424236746, 'solver': 'newton-cg', 'max_iter': 182}\n",
      "{'n_estimators': 338, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Optuna giperparametr optimallashtiruvchi funksiyalar\n",
    "\n",
    "# Decision Tree\n",
    "def objective_dt(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "    splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        splitter=splitter,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=1\n",
    "    )\n",
    "    score = cross_val_score(dt, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    return score\n",
    "\n",
    "# Logistic Regression\n",
    "def objective_lr(trial):\n",
    "    C = trial.suggest_loguniform('C', 1e-4, 1e4)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs', 'newton-cg'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "    \n",
    "    lr = LogisticRegression(\n",
    "        C=C, \n",
    "        solver=solver, \n",
    "        max_iter=max_iter, \n",
    "        random_state=1\n",
    "    )\n",
    "    score = cross_val_score(lr, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    return score\n",
    "\n",
    "# Random Forest\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 400)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 15)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=1\n",
    "    )\n",
    "    score = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    return score\n",
    "\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_lr = optuna.create_study(direction='maximize')\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "\n",
    "study_dt.optimize(objective_dt, n_trials=50)\n",
    "study_lr.optimize(objective_lr, n_trials=50)\n",
    "study_rf.optimize(objective_rf, n_trials=50)\n",
    "\n",
    "print(study_dt.best_params)\n",
    "print(study_lr.best_params)\n",
    "print(study_rf.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8911312905583811\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_dt = DecisionTreeClassifier(**study_dt.best_params, random_state=1)\n",
    "best_lr = LogisticRegression(**study_lr.best_params, random_state=1)\n",
    "best_rf = RandomForestClassifier(**study_rf.best_params, random_state=1)\n",
    "\n",
    "estimators = [('dt', best_dt), ('lr', best_lr), ('rf', best_rf)]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'ROC AUC Score: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topilgan eng yaxshi parametrlar orqali pipeline orqali ozimiz model qilib olamiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.8862172598529259\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=1, max_depth=8, min_samples_leaf=3, min_samples_split=5, max_features='log2', criterion='entropy')\n",
    "lr = LogisticRegression(random_state=1, C=np.float64(0.03359818286283781), max_iter=200, solver='newton-cg')\n",
    "rf = RandomForestClassifier(random_state=1, criterion='entropy', max_depth=15, max_features='log2', \n",
    "                            min_samples_leaf=2, min_samples_split=7, n_estimators=400)\n",
    "\n",
    "estimators = [\n",
    "    ('dt', Pipeline([('scaler', StandardScaler()), ('dt', dt)])),\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('lr', lr)])),\n",
    "    ('rf', Pipeline([('scaler', StandardScaler()), ('rf', rf)]))\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator = RandomForestClassifier(random_state=1, criterion='entropy', max_depth=12, max_features='log2', \n",
    "                            min_samples_leaf=2, min_samples_split=7, n_estimators=400)\n",
    ")\n",
    "\n",
    "# Modelni o'rgatish\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'ROC AUC Score: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "train_sizes, train_scores, val_scores = learning_curve(stacking_clf, X_train, y_train,\n",
    "                                                      cv=skf, scoring='roc_auc', train_sizes=np.linspace(0.1, 1.0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes, train_mean, marker='o', label='Train ROC AUC', color='blue')\n",
    "plt.plot(train_sizes, val_mean, marker='o', label='Validation ROC AUC', color='orange')\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color='orange', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('ROC AUC Score')\n",
    "plt.title('Learning Curve: Train vs Validation ROC AUC')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = stacking_clf.predict_proba(df_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample['smoking'] = y_pred_proba\n",
    "# sample.to_csv('1-urinish.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
